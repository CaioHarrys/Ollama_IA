# Ollama_IA 🚀🧠

Repositório para integração e uso local de modelos de linguagem (LLMs) através do **[Ollama](https://ollama.com/)**, uma plataforma que permite rodar modelos de IA diretamente no seu computador, sem depender da nuvem.

---

## 📜 Descrição

Este projeto demonstra como utilizar a API do Ollama para interagir com modelos de linguagem de forma local via Python.

Com este script, você pode enviar perguntas ou comandos para um modelo AI rodando na sua máquina, obtendo respostas rapidamente, com total controle dos dados e sem necessidade de conexão externa.

---

## 🛠️ Tecnologias e Ferramentas

- 🐍 **Python 3.10+**
- 🔗 **API REST do Ollama**
- 📦 **Bibliotecas Python:**
  - `requests`

---

## 🚀 Instalação e Execução

### 🔧 Pré-requisitos
- Ter o **[Ollama](https://ollama.com/) instalado** na sua máquina (Windows, macOS ou Linux).
- Ter um modelo baixado (ex.: `llama3`, `mistral`, `phi`, `llama2`, etc.).

### 📥 Clone o repositório:
```bash
git clone https://github.com/CaioHarrys/Ollama_IA.git
cd Ollama_IA
