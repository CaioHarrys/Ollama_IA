# Ollama_IA ğŸš€ğŸ§ 

RepositÃ³rio para integraÃ§Ã£o e uso local de modelos de linguagem (LLMs) atravÃ©s do **[Ollama](https://ollama.com/)**, uma plataforma que permite rodar modelos de IA diretamente no seu computador, sem depender da nuvem.

---

## ğŸ“œ DescriÃ§Ã£o

Este projeto demonstra como utilizar a API do Ollama para interagir com modelos de linguagem de forma local via Python.

Com este script, vocÃª pode enviar perguntas ou comandos para um modelo AI rodando na sua mÃ¡quina, obtendo respostas rapidamente, com total controle dos dados e sem necessidade de conexÃ£o externa.

---

## ğŸ› ï¸ Tecnologias e Ferramentas

- ğŸ **Python 3.10+**
- ğŸ”— **API REST do Ollama**
- ğŸ“¦ **Bibliotecas Python:**
  - `requests`

---

## ğŸš€ InstalaÃ§Ã£o e ExecuÃ§Ã£o

### ğŸ”§ PrÃ©-requisitos
- Ter o **[Ollama](https://ollama.com/) instalado** na sua mÃ¡quina (Windows, macOS ou Linux).
- Ter um modelo baixado (ex.: `llama3`, `mistral`, `phi`, `llama2`, etc.).

### ğŸ“¥ Clone o repositÃ³rio:
```bash
git clone https://github.com/CaioHarrys/Ollama_IA.git
cd Ollama_IA
